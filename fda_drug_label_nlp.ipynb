{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabee05/scispacy-nlp/blob/main/fda_drug_label_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LYyZYggpMjy",
        "outputId": "e719cf00-43c0-4eb3-a081-45bd8ddf1e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version\n",
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "Version info.\n",
            "sys.version_info(major=3, minor=10, micro=12, releaselevel='final', serial=0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(f"Python version: {sys.version}")\n",
        "print(f"Version info: {sys.version_info}")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can mount your Google Drive if you want to persist the files; otherwise, files will be saved temporarily on the runtime instance.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1IkpbEagLZ-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9hdXE1QWnQL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install scispacy tika\n",
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1wqIFICz3uK"
      },
      "outputs": [],
      "source": [
        "# This model was trained on the JNLPBA corpus for entities like DNA,Cell type,Cell line,RNA,Protein (GENE)\n",
        "\n",
        "%%capture\n",
        "!pip install 'https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_jnlpba_md-0.5.1.tar.gz'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ8bsQtNz8PM"
      },
      "outputs": [],
      "source": [
        "# this model was trained on BC5CDR corpus for Disease and Chemical entities (DRUG)\n",
        "\n",
        "%%capture\n",
        "!pip install 'https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zEQei2Qz_t3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install 'https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz'\n",
        "#!pip install 'https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bionlp13cg_md-0.5.0.tar.gz'\n",
        "\n",
        "#Trained on the BIONLP13CG corpus for about 16 types of entities like Organ, Organism,Cell,Cancer,Cellular Component,Pathological_formation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuYXyv1rxU4-"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import scispacy\n",
        "import en_ner_jnlpba_md\n",
        "import en_ner_bc5cdr_md\n",
        "import en_ner_bionlp13cg_md\n",
        "import requests\n",
        "import os\n",
        "import re\n",
        "import fitz\n",
        "import pandas as pd\n",
        "import json\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drug_label_list = \"\"\"\n",
        "[\n",
        "    {\n",
        "        \"document_id\": \"021588s062lbl\",\n",
        "        \"document_url\": \"https://www.accessdata.fda.gov/drugsatfda_docs/label/2022/021588s062lbl.pdf\",\n",
        "        \"skip\": false\n",
        "    },\n",
        "    {\n",
        "        \"document_id\": \"125084s279lbl\",\n",
        "        \"document_url\": \"https://www.accessdata.fda.gov/drugsatfda_docs/label/2021/125084s279lbl.pdf\",\n",
        "        \"skip\": false\n",
        "    },\n",
        "    {\n",
        "        \"document_id\": \"211710s008lbl\",\n",
        "        \"document_url\": \"https://www.accessdata.fda.gov/drugsatfda_docs/label/2022/211710s008lbl.pdf\",\n",
        "        \"skip\": false\n",
        "    },\n",
        "    {\n",
        "        \"document_id\": \"212725s006lbl\",\n",
        "        \"document_url\": \"https://www.accessdata.fda.gov/drugsatfda_docs/label/2022/212725s006lbl.pdf\",\n",
        "        \"skip\": false\n",
        "    }\n",
        "]\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "iyZlFlaEfqSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR= \"/content/\"\n",
        "INPUT_DIR = \"/content/\"\n",
        "OUTPUT_DIR = \"/content/\"\n"
      ],
      "metadata": {
        "id": "6XXwF4BIn91u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downloader(url, folder):\n",
        "    \"\"\"\n",
        "    Downloads a file from the given URL and saves it to the specified folder.\n",
        "\n",
        "    Args:\n",
        "    url (str): The URL of the file to be downloaded.\n",
        "    folder (str): The path to the folder where the file should be saved.\n",
        "\n",
        "    Returns:\n",
        "    str or None: The path to the downloaded file if successful, or None if an error occurs.\n",
        "\n",
        "    The function attempts to download a file from the provided URL. If the download is successful,\n",
        "    the file is saved in the specified folder with its original name extracted from the URL.\n",
        "    If the download fails due to HTTP errors, request issues, or file write errors, it prints an\n",
        "    error message and returns None. It handles HTTP errors, request exceptions, and file write\n",
        "    (OSError) exceptions separately.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            file_path = os.path.join(folder, url.split(\"/\")[-1])\n",
        "            with open(file_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            return file_path\n",
        "        else:\n",
        "            print(f\"Error {response.status_code}: Unable to download document from {url}\")\n",
        "            return None\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request error: {e}\")\n",
        "        return None\n",
        "    except OSError as e:\n",
        "        print(f\"File operation error: {e}\")\n",
        "        return None\n",
        "\n",
        "#help(downloader)"
      ],
      "metadata": {
        "id": "73UrajZ0fKx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pdf(input_file: str, pages: Tuple = None):\n",
        "    out_json = {}\n",
        "\n",
        "    try:\n",
        "        pdfDoc = fitz.open(input_file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening PDF file: {e}\")\n",
        "        return None\n",
        "\n",
        "    full_text_processed = ''\n",
        "\n",
        "    try:\n",
        "        for pg in range(pdfDoc.page_count):\n",
        "            if pages and str(pg) not in pages:\n",
        "                continue\n",
        "            page = pdfDoc[pg]\n",
        "            page_text = page.get_text(\"text\")\n",
        "\n",
        "            try:\n",
        "                first_nonNewLine_pos = re.search(\"[A-Za-z]\", page_text)\n",
        "                if first_nonNewLine_pos:\n",
        "                    page_text_to_keep = page_text[first_nonNewLine_pos.start():]\n",
        "                    full_text_processed += '\\n' + page_text_to_keep\n",
        "            except re.error as e:\n",
        "                print(f\"Regular expression error: {e}\")\n",
        "                continue\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing PDF file: {e}\")\n",
        "        return None\n",
        "    finally:\n",
        "        pdfDoc.close()\n",
        "\n",
        "    out_json['text'] = full_text_processed\n",
        "    return out_json\n"
      ],
      "metadata": {
        "id": "x6CfYjJSwp5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_documents(json_input):\n",
        "\n",
        "    try:\n",
        "        documents = json.loads(json_input)\n",
        "    except json.JSONDecodeError:\n",
        "        try:\n",
        "            with open(json_input, 'r') as f:\n",
        "                documents = json.load(f)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: Unable to process input as JSON or file path. Reason: {e}\")\n",
        "            return\n",
        "\n",
        "    for document in documents:\n",
        "      try:\n",
        "        if not document.get('skip', False):\n",
        "            document_id = document['document_id']\n",
        "            document_url = document['document_url']\n",
        "            if not os.path.exists(document_id):\n",
        "              os.makedirs(document_id)\n",
        "            if os.path.isfile(document_id + '/' + document_id + '.pdf'):\n",
        "              print(\"The drug lable is already downloaded to {0}\".format(document_id + '/' + document_id + '.pdf'))\n",
        "              pdf_file=os.path.join(document_id, f\"{document_id}.pdf\")\n",
        "            else:\n",
        "                print(\"The drug lable was downloaded successfully to {0}\".format(document_id + '/' + document_id + '.pdf'))\n",
        "                pdf_file=downloader(document_url, document_id)\n",
        "\n",
        "            if pdf_file:\n",
        "                out_json = extract_pdf(pdf_file)\n",
        "                out_json['text']=re.sub(\"([A-Za-z]) \\n([A-Za-z])\", r\"\\1 \\2\", out_json['text'])\n",
        "                with open(os.path.join(document_id, f\"{document_id}.json\"), \"w\") as OF:\n",
        "                    json.dump(out_json, OF)\n",
        "\n",
        "      except Exception as e:\n",
        "        print(f\"Error: Unable to download and process document from {document_url}. Reason: {e}\")\n"
      ],
      "metadata": {
        "id": "S5EEu7RvfdxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_documents(drug_label_list)"
      ],
      "metadata": {
        "id": "3dSYER70iWsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffd1bd0-56cb-43fd-b22f-8a8a7abd8cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The drug lable is already downloaded to 021588s062lbl/021588s062lbl.pdf\n",
            "The drug lable is already downloaded to 125084s279lbl/125084s279lbl.pdf\n",
            "The drug lable is already downloaded to 211710s008lbl/211710s008lbl.pdf\n",
            "The drug lable is already downloaded to 212725s006lbl/212725s006lbl.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrhS0I_turVb"
      },
      "outputs": [],
      "source": [
        "nlp_bionlp13cg = en_ner_bionlp13cg_md.load()\n",
        "nlp_jnlpba = en_ner_jnlpba_md.load()\n",
        "nlp_bc5cdr = en_ner_bc5cdr_md.load()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_from_json(folder, file_name):\n",
        "    file_name = os.path.join(folder, f\"{file_name}.json\")\n",
        "    if os.path.isfile(file_name):\n",
        "        try:\n",
        "            with open(file_name, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "                return data.get(str('text'))\n",
        "        except Exception as e:\n",
        "            print(f\"Error while reading file {file_name}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "nhTKcUb-eVDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text_with_models(text, models, label_dict, document_id, filter=False):\n",
        "    list_of_files =[]\n",
        "    for model in models:\n",
        "        try:\n",
        "            model_name = [name for name in globals() if globals()[name] is model][0]\n",
        "            print(f\"Running {model_name} for {document_id}\")\n",
        "            doc = model(text)\n",
        "            entity_and_label = set([(ent.text, ent.label_) for ent in doc.ents])\n",
        "            entity_and_label_pos = list([(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents])\n",
        "\n",
        "            if filter:\n",
        "                entity_and_label = [(ent, lbl) for ent, lbl in entity_and_label if lbl in label_dict.keys()]\n",
        "                entity_and_label_pos = [(start, end, label_dict.get(lbl, lbl)) for start, end, lbl in entity_and_label_pos if lbl in label_dict.keys()]\n",
        "\n",
        "            if len(entity_and_label) > 0:\n",
        "              entity_and_label = [(ent, lbl, label_dict.get(lbl, lbl)) for ent, lbl in entity_and_label]\n",
        "              entity_and_label_df = pd.DataFrame(entity_and_label, columns=['Entity','Original_Label', 'Mapped_Label'])\n",
        "              entity_and_label_pos_df = pd.DataFrame(entity_and_label_pos, columns=['Start', 'End','Label'])\n",
        "              entity_and_label_df['Model_Name'] = model_name\n",
        "              entity_and_label_pos_df['Model_Name'] = model_name\n",
        "\n",
        "              entity_and_label_df.to_csv(f'{document_id}/{document_id}_{model_name}.csv', index=False)\n",
        "              entity_and_label_pos_df.to_csv(f'{document_id}/{document_id}_{model_name}_pos.csv', index=False)\n",
        "\n",
        "              list_of_files.append(f'{document_id}/{document_id}_{model_name}.csv')\n",
        "              output_file = os.path.join(f'{document_id}/{document_id}.json')\n",
        "\n",
        "\n",
        "            if os.path.isfile(output_file) and len(entity_and_label_pos) > 0:\n",
        "                with open(output_file, 'r', encoding='utf-8') as f:\n",
        "                    existing_data = json.load(f)\n",
        "\n",
        "                existing_data[\"label\"] = existing_data.get(\"label\", []) + entity_and_label_pos\n",
        "\n",
        "                with open(f\"{document_id}/{document_id}_{model_name}_doccano.json\", 'w', encoding='utf-8') as f:\n",
        "                    json.dump(existing_data, f, ensure_ascii=False, indent=2)\n",
        "            else:\n",
        "                print(f\"File or entities were not found: {document_id}\")\n",
        "\n",
        "            print(f\"Completed {model_name} for {document_id} \\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing text with model '{model_name}': {e}\")\n",
        "\n",
        "    print(list_of_files)\n",
        "    return list_of_files"
      ],
      "metadata": {
        "id": "pqldDifQjP5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For mapping built-in NER labels to normalized labels\n",
        "\n",
        "label_dict = {\n",
        "   \"CANCER\": \"DISEASE\",\n",
        "   \"GENE_OR_GENE_PRODUCT\": \"GENE\",\n",
        "   \"GENE_OR_GENE_PRODUCT_FAMILY\": \"GENE\",\n",
        "   \"CHEMICAL\": \"DRUG\"\n",
        "   }\n",
        "\n",
        "models = [nlp_bionlp13cg, nlp_jnlpba, nlp_bc5cdr]\n"
      ],
      "metadata": {
        "id": "kVwL_KWszM0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_drug_lable(json_input):\n",
        "    try:\n",
        "        documents = json.loads(json_input)\n",
        "    except json.JSONDecodeError:\n",
        "        try:\n",
        "            with open(json_input, 'r') as f:\n",
        "                documents = json.load(f)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: Unable to process input as JSON or file path. Reason: {e}\")\n",
        "            return\n",
        "    for document in documents:\n",
        "      try:\n",
        "        if not document.get('skip', False):\n",
        "            document_id = document['document_id']\n",
        "            document_url = document['document_url']\n",
        "            text=get_text_from_json(document_id, document_id)\n",
        "            processed_files=process_text_with_models(text,models,label_dict, document_id, filter=False)\n",
        "      except Exception as e:\n",
        "        print(f\"Error: Unable to download and process document from {document_url}. Reason: {e}\")"
      ],
      "metadata": {
        "id": "FROzLgvOyZkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_drug_lable(drug_label_list)"
      ],
      "metadata": {
        "id": "ytH2axI0zRBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf0e853-22fc-4e59-907b-5a449602f466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running nlp_bionlp13cg for 021588s062lbl\n",
            "Completed nlp_bionlp13cg for 021588s062lbl \n",
            "\n",
            "Running nlp_jnlpba for 021588s062lbl\n",
            "Completed nlp_jnlpba for 021588s062lbl \n",
            "\n",
            "Running nlp_bc5cdr for 021588s062lbl\n",
            "Completed nlp_bc5cdr for 021588s062lbl \n",
            "\n",
            "['021588s062lbl/021588s062lbl_nlp_bionlp13cg.csv', '021588s062lbl/021588s062lbl_nlp_jnlpba.csv', '021588s062lbl/021588s062lbl_nlp_bc5cdr.csv']\n",
            "Running nlp_bionlp13cg for 125084s279lbl\n",
            "Completed nlp_bionlp13cg for 125084s279lbl \n",
            "\n",
            "Running nlp_jnlpba for 125084s279lbl\n",
            "Completed nlp_jnlpba for 125084s279lbl \n",
            "\n",
            "Running nlp_bc5cdr for 125084s279lbl\n",
            "Completed nlp_bc5cdr for 125084s279lbl \n",
            "\n",
            "['125084s279lbl/125084s279lbl_nlp_bionlp13cg.csv', '125084s279lbl/125084s279lbl_nlp_jnlpba.csv', '125084s279lbl/125084s279lbl_nlp_bc5cdr.csv']\n",
            "Running nlp_bionlp13cg for 211710s008lbl\n",
            "Completed nlp_bionlp13cg for 211710s008lbl \n",
            "\n",
            "Running nlp_jnlpba for 211710s008lbl\n",
            "Completed nlp_jnlpba for 211710s008lbl \n",
            "\n",
            "Running nlp_bc5cdr for 211710s008lbl\n",
            "Completed nlp_bc5cdr for 211710s008lbl \n",
            "\n",
            "['211710s008lbl/211710s008lbl_nlp_bionlp13cg.csv', '211710s008lbl/211710s008lbl_nlp_jnlpba.csv', '211710s008lbl/211710s008lbl_nlp_bc5cdr.csv']\n",
            "Running nlp_bionlp13cg for 212725s006lbl\n",
            "Completed nlp_bionlp13cg for 212725s006lbl \n",
            "\n",
            "Running nlp_jnlpba for 212725s006lbl\n",
            "Completed nlp_jnlpba for 212725s006lbl \n",
            "\n",
            "Running nlp_bc5cdr for 212725s006lbl\n",
            "Completed nlp_bc5cdr for 212725s006lbl \n",
            "\n",
            "['212725s006lbl/212725s006lbl_nlp_bionlp13cg.csv', '212725s006lbl/212725s006lbl_nlp_jnlpba.csv', '212725s006lbl/212725s006lbl_nlp_bc5cdr.csv']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
